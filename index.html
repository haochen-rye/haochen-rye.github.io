
<!DOCTYPE html>
<html>
<style>

p {
  font-size: 15px;
}

</style>

<head lang="en">
    <meta charset="UTF-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">

    <title>Hao Chen</title>

    <meta name="hao chen umd" content="">
    <meta name="viewport" content="width=device-width, initial-scale=1.">


<!--     <link rel="apple-touch-icon" href="apple-touch-icon.png"> -->
  <link rel="icon" type="image/png" href="img/seal_icon.png">
    <!-- Place favicon.ico in the root directory -->

    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap.min.css">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.css">
    <link rel="stylesheet" href="css/app.css">
    <link rel="stylesheet" href="css/bootstrap.min.css">
    
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-110862391-1"></script>
    <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-110862391-1');
    </script>

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/js/bootstrap.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/1.5.3/clipboard.min.js"></script>
    
    <script src="js/app.js"></script>
</head>

<body>
    <div class="container" id="main" >
        <div class="row">
            <h2 class="col-md-12 text-center">
                <font size="+3"> Hao Chen  <img style="height:60px;" align="top" src="./images/L.jpeg"> </font> </br>                 
                <small>
                    Èôà Ë±™ <br> 
                    haochen.umd@gmail.com
                </small>

            </h2>
            <h4 class="col-md-12 text-center">
            <ul class="list-inline">
                <a href="images/hao_cv.pdf">CV &nbsp; / &nbsp;</a>
                <a href="https://scholar.google.com/citations?user=QMuIRLYAAAAJ&hl=en">Google Scholar &nbsp; / &nbsp; </a>
                <a href="https://github.com/haochen-rye">Github &nbsp; / &nbsp;</a>
                <a href="https://www.linkedin.com/in/hao-chen-a541b41a2/">Linkedin &nbsp; / &nbsp;</a>
                <a href="images/LMM_intern.pdf">Hiring &nbsp; &nbsp;</a>
                <br>
            </ul>
                <!-- <a href="http://www.cs.umd.edu/"></font>Department of Computer Science, University of Maryland </a><br>             -->
            </h4>
        </div>


        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <p class="text-justify">
                    <span style=" font-weight:bold;">
                        ‚≠ê üöÄ üî• We are excited to welcome passionate Research Interns to join our team, working on cutting-edge multi-modality models and vision representation! If you‚Äôre interested in innovative research and eager to make an impact, please feel free to reach out via email. üî• üöÄ ‚≠ê                    </span>
                    <br><br>
                    I am currently a Research Scientist at ByteDance. Before this, I worked as a Postdoctoral Researcher at Meta.                    
                    I earned my Ph.D. in Computer Science from the University of Maryland, College Park, under the guidance of <a href="http://www.cs.umd.edu/~abhinav/">Prof. Abhinav Shrivastava</a>.
                    Prior to this, I completed my Master's degree in Pattern Recognition & Intelligent Systems at <a href="http://english.hust.edu.cn">Huazhong University of Science & Technology</a> (HUST)
                    , supervised by <a href="https://www.researchgate.net/profile/Guoyou_Wang">Prof. Guoyou Wang</a>. 
                    I also hold a Bachelor's degree from the School of <a href=http://english.oei.hust.edu.cn/>Optical and Electronic Information</a> at HUST.
                    <br> <br>
                    My research primarily focuses on implicit video representation, compression techniques, efficient deployment of neural networks.             
                    During the PhD, I proposed an image-wise implicit neural representation for videos and have been building an implicit framework based on it. 
                    I envision this implicit space functioning similarly to the Fourier Transform in signal processing, 
                    offering new perspectives and facilitating various tasks in video processing. 
                    These tasks include compression, enhancement, processing, analysis, and generation of videos. 
                    Additionally, this framework can be applied to many other types of sequential data, such as aerial and medical imagery videos, dynamic point clouds.
                </p>
            </div>
        </div>


        <h2>    
            <p class="text-justify">
            
            <section0>                
                Projects by areas: &nbsp;&nbsp;        
            </section0>
            <section1>   
                <a href="index.html" style="color:red;">  Neural Representation</a> &nbsp;&nbsp;&nbsp;
            </section1>
            <section2>   
                <a href="efficient_archi.html"> Efficent Architecture</a> &nbsp;&nbsp;&nbsp;
                <a href="object_detection.html">Object Detection</a> &nbsp;&nbsp;&nbsp;
            </section2>
            <!-- <a href="blog.html" >Blogs</a> &nbsp;&nbsp; -->
            <br>
            </p>

        </h2>

        <div class="paper" style="float:left; display:inline-block; margin-top: 25px;"> 
            <span style="float:left;width: 40%;">
                <img src="images/fastnerv.jpg" alt="" width="100%" >
            </span>
            <span style="float:right;width: 58%;">
                <p style="float:left; display:block;" >
                <heading style="color:blue;"><strong>Fast Encoding and Decoding for Implicit Video Representation </strong> </heading><br>
            <strong>ECCV 2024
                <a href="https://haochen-rye.github.io/FastNeRV">[project page]</a>
                <a href="https://arxiv.org/abs/2409.19429">[preprint paper]  </a>
                <a href="https://github.com/haochen-rye/FastNeRV">[code]</a>
            </strong> <br> 
                <strong>Hao Chen</strong>, Saining Xie, Ser-Nam Lim, Abhinav Shrivastava         <br style="line-height:125%"> </br>    
                We propose NeRV-Enc, which encodes videos 10<sup>4</sup>  times faster than its predecessor NeRV, utilizing hyper-networks. 
                Additionally, we introduce NeRV-Dec, which decodes video 8.9 times faster than NeRV via parallel decoding,
                 and is 11 times faster compared to the H.264 codec.
            </p>
            </span>
        </div>

        <div class="paper" style="float:left; display:inline-block; margin-top: 25px;"> 
            <span style="float:left;width: 40%;">
                <img src="images/hnerv-teaser.png" alt="" width="100%" >
            </span>
            <span style="float:right;width: 58%;">
                <p style="float:left; display:block;" >
                <heading style="color:blue;"><strong>HNeRV: A Hybrid Neural Representation for Videos </strong> </heading><br>
            <strong>CVPR 2023
                <a href="https://haochen-rye.github.io/HNeRV">[project page]</a>
                <a href="https://arxiv.org/abs/2304.02633">[paper] 
                <a href="https://github.com/haochen-rye/HNeRV.git">[code]</a>
            </strong> <br>
                <strong>Hao Chen</strong>, Matt Gwilliam, Ser-Nam Lim, Abhinav Shrivastava         <br style="line-height:125%"> </br>    
            We propose a hybrid video neural representation and a evenly distributed neural network to improve modeling capacity and introduce internal generalization.   
                </p>
            </span>
        </div>

        <div class="paper" style="float:left; display:inline-block; margin-top: 25px;"> 
            <span style="float:left;width: 40%;">
                <img src="https://i.imgur.com/dY0YKLe.jpg" alt="" width="100%" >
            </span>
            <span style="float:right;width: 58%;">
                <p style="float:left; display:block;" >
                <heading style="color:blue;"><strong>Towards Scalable Neural Representation for Diverse Videos </strong> </heading><br>
            <strong>CVPR 2023
                <a href="https://boheumd.github.io/D-NeRV">[project page]</a>
                <a href="https://arxiv.org/abs/2303.14124">[paper] 
                <a href="https://github.com/boheumd/D-NeRV">[code]</a>
            </strong> <br>
                Bo He, Xitong Yang, Hanyu Wang, Zuxuan Wu, <strong>Hao Chen</strong>, Shuaiyi Huang, Yixuan Ren, Ser-Nam Lim, Abhinav Shrivastava  <br style="line-height:125%"> </br>    
                We propose D-NeRV, a novel neural representation framework designed to encode large-scale and diverse videos. 
                </p>
            </span>
        </div>        
    
        <div class="paper" style="float:left; display:inline-block; margin-top: 25px;"> 
            <span style="float:left;width: 40%;">
                <img src="images/cnerv_teaser.jpg" alt="" width="100%" >
            </span>
            <span style="float:right;width: 58%;">
                <p style="float:left; display:block;" >
            <heading style="color:blue;"><strong>CNeRV: Content-adaptive Neural Representation for Visual Data </strong> </heading><br>
            <strong>BMVC 2022 (Oral)
                <a href="https://haochen-rye.github.io/CNeRV">[project page]
                <a href="http://128.84.21.203/abs/2211.10421">[paper] 
                </a> </strong> <br>
            <strong>Hao Chen</strong>, Matt Gwilliam, Bo He, Ser-Nam Lim, Abhinav Shrivastava       <br style="line-height:125%"> </br>     
            We propose a hybrid video neural representation with content-adaptive embedding to introduce internal generalization.   
                </p>
            </span>
        </div>


        <div class="paper" style="float:left; display:inline-block; margin-top: 25px; margin-bottom: 50px;"> 
            <span style="float:left;width: 40%;">
                <img src="images/nerv_teaser.png" alt="" width="100%" >
            </span>
            <span style="float:right;width: 58%;">
                <p style="float:left; display:block;" >
            <heading style="color:blue;"><strong>NeRV: Neural Representations for Videos </strong> </heading><br>
            <strong>NeurIPS 2021 
                <a href="https://haochen-rye.github.io/NeRV">[project page]
                <a href="https://arxiv.org/abs/2110.13903">[paper]
                </a><a href="https://github.com/haochen-rye/NeRV.git">[code]</a></strong> <br>          
            <strong>Hao Chen</strong>, Bo He, Hanyu Wang, Yixuan Ren, Ser-Nam Lim, Abhinav Shrivastava     <br style="line-height:125%"> </br>    
            We propose an image-wise neural representation for videos, which achieves good compression results and fast decoding speed.
            </p>
            </span>
        </div>




         <table width="100%" align="center" border="2" cellspacing="10" cellpadding="10" >
            <h4 >Acknowledge</h4>
            <p class="text-justify">
            I appreciate everyone who  helped me or encouraged me throughout my life, especially  <a href="http://www.cs.umd.edu/~abhinav/">Prof. Abhinav Shrivastava</a>, 
            <a href="https://www.researchgate.net/profile/Guoyou_Wang">Prof. Guoyou Wang</a>, 
            <a href=http://english.siat.cas.cn/SI2017/IAIT2017/RC1/CPE_20513/Researchers1/201707/t20170724_181172.html> Prof. Yu Qiao</a>,
            <a href=http://english.siat.cas.cn/SI2017/IAIT2017/RC1/CPE_20513/Researchers1/201707/t20170727_181385.html> Prof. Yali Wang</a>,
            <a href=http://cloud.eic.hust.edu.cn:8071/~xbai/> Prof. Xiang Bai </a> 
            and all good friends I met at China and the US.
                </p>
                    </td>
                </tr>
            </table>        

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <br> The website template was borrowed from <a href="https://bmild.github.io">Ben Mildenhall</a>.
                </p>
            </div>
        </div>
    </div>
</body>
</html>
